{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../../README.md)\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "This Jupyter Notepad is a selection of data engineering processes you can apply to your data before model training to maximise the performance of your machine learning model. For this demonstration we will engineer new or improved features for the diabetes data you previously wrangled.\n",
    "\n",
    "#### Feature Engineering Process\n",
    "- Deriving new variables from existing ones\n",
    "    - Encoding categorical features\n",
    "    - Calculating new features from existing features\n",
    "- Combining features/feature interactions\n",
    "- Identifying the most relevant features for the model\n",
    "- Transforming Features\n",
    "  - [Dividing Data into categories](https://web.ma.utexas.edu/users/mks/statmistakes/dividingcontinuousintocategories.html)\n",
    "  - Mathematical transformations (for example logarithmic transformations). Logarithmic transformations are a powerful tool in the world of statistical analysis. They are often used to transform data that exhibit skewness or other irregularities, making it easier to analyze, visualize, and interpret the results.\n",
    "- Creating Domain-Specific Features that incorporating knowledge from the specific domain to create features that capture important characteristics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"2.2.1.wrangled_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Deriving new variables from existing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding categorical variables\n",
    "\n",
    "Data Encoding converts textual data into numerical format, so that it can be used as input for algorithms to process. The reason for encoding is that most machine learning algorithms work with numbers and not with text or categorical variables.\n",
    "\n",
    "To encode the 'SEX' column you will assigning a number value to the gender. Because the data set only provides 2 values we will use -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2   -1\n",
      "3   -1\n",
      "4   -1\n",
      "Name: SEX, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda gender: -1 if gender.lower() == 'male' else 1 if gender.lower() == 'female' else None)\n",
    "print(data_frame['SEX'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating Age\n",
    "\n",
    "In the context of medical diagnosis of a lifestyle disease a persons date of birth has limited influence on the target. However, their age is highly relevant. So we will convert two dates into a age. You could consider further encoding this into age brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           DoB        DoT   Age\n",
      "0   2001-06-17 2024-10-09  23.0\n",
      "1   1995-06-10 2024-08-16  29.0\n",
      "2   1981-03-11 2024-03-08  43.0\n",
      "3   2002-05-15 2024-05-06  22.0\n",
      "4   2001-06-21 2024-07-20  23.0\n",
      "..         ...        ...   ...\n",
      "422 1955-04-06 2024-04-12  69.0\n",
      "423 1962-06-22 2024-09-14  62.0\n",
      "424 1966-08-26 2024-11-27  58.0\n",
      "425 1980-04-28 2024-04-03  44.0\n",
      "426 1987-06-13 2024-06-09  37.0\n",
      "\n",
      "[427 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'DoB' and 'DoTest' columns to datetime\n",
    "data_frame['DoB'] = pd.to_datetime(data_frame['DoB'], format='%d/%m/%Y')\n",
    "data_frame['DoT'] = pd.to_datetime(data_frame['DoT'], format='%d/%m/%Y')\n",
    "\n",
    "# Calculate the year difference\n",
    "data_frame['Age'] = ((data_frame['DoT'] - data_frame['DoB']).dt.days  / 365.25).round()\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['DoB', 'DoT', 'Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining features/feature interactions\n",
    "\n",
    "While individual features can be powerful predictors, their interactions often carry even more information. Feature interaction engineering is the process of creating new features that represent the interaction between two or more features.\n",
    "\n",
    "In this, case some domain knowledge and data analysis have informed you that the BMI and AGE are risk multipliers (the greater the age and the greater the BMI the greater the feature). From this we can  risk value based on the feature interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age       BMI  Risk%\n",
      "0     23  0.115385   0.05\n",
      "1     29  0.119231   0.06\n",
      "2     43  0.134615   0.10\n",
      "3     22  0.138462   0.05\n",
      "4     23  0.146154   0.06\n",
      "..   ...       ...    ...\n",
      "422   69  0.846154   1.00\n",
      "423   62  0.876923   0.93\n",
      "424   58  0.884615   0.88\n",
      "425   44  0.892308   0.67\n",
      "426   37  0.896154   0.57\n",
      "\n",
      "[427 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the year difference and round to an integer\n",
    "data_frame['Age'] = ((data_frame['DoT'] - data_frame['DoB']).dt.days / 365.25).round().astype(int)\n",
    "\n",
    "# Create the 'Risk' column\n",
    "data_frame['Risk'] = data_frame['BMI'] * data_frame['Age']\n",
    "\n",
    "# Calculate the percentage of the maximum risk\n",
    "data_frame['Risk%'] = (data_frame['Risk'] / data_frame['Risk'].max()).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Age', 'BMI', 'Risk%']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Features\n",
    "\n",
    "Filtering is like applying the where clause in a database. It is widely used and can help when you need to work on a specific subset of your data. For our use case, let us filter the data to only include rows where the 'SEX' is 'Male'. There is no method call for this, we can just use conditional indexing to fulfil our purpose.\n",
    "\n",
    "In this, case some domain knowledge and data analysis have informed you that there is 'bimodality' in the data and males and females have a different trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  SEX    Target\n",
      "2     43   -1  0.215385\n",
      "3     22   -1  0.249231\n",
      "4     23   -1  0.200000\n",
      "5     26   -1  0.095385\n",
      "8     19   -1  0.360000\n",
      "..   ...  ...       ...\n",
      "416   43   -1  0.784615\n",
      "419   57   -1  0.769231\n",
      "420   55   -1  0.732308\n",
      "422   69   -1  0.667692\n",
      "426   37   -1  0.735385\n",
      "\n",
      "[228 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the data to -1 only\n",
    "data_frame = data_frame[data_frame['SEX'] == -1]\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Age', 'SEX', 'Target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Domain-Specific Features\n",
    "\n",
    "Domain knowledge is about understanding the domain or subject area of the data. In This case the domain is 'health' and more specifically   'Epidemiology' which is the study of how often diseases occur in different groups of people and why.\n",
    "\n",
    "The column called '1st Degree Relatives' is a domain specific feature as is records the number of family members in the individuals direct bloodline who have developed type 2 adult onset diabetes. Domain specific knowledge, is that Family history of disease in first degree relatives is a major risk factor, especially for premature events.\n",
    "\n",
    "First we will convert we will convert the FDR value to a risk percentage, because the risk can never be 0 (will never happen) or 100% (will definitely happen) we will scale the result between 0.15 and 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age   FDR  FHRisk\n",
      "2     43  0.50    0.62\n",
      "3     22  0.50    0.62\n",
      "4     23  0.50    0.62\n",
      "5     26  0.50    0.62\n",
      "8     19  0.00    0.15\n",
      "..   ...   ...     ...\n",
      "416   43  0.00    0.15\n",
      "419   57  0.25    0.38\n",
      "420   55  0.50    0.62\n",
      "422   69  0.50    0.62\n",
      "426   37  0.00    0.15\n",
      "\n",
      "[228 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the family history risk\n",
    "data_frame['FHRisk'] = (data_frame['FDR'] / data_frame['FDR'].max())\n",
    "\n",
    "# Scale the result between 0.15 and 0.85\n",
    "min_val = 0.15\n",
    "max_val = 0.85\n",
    "data_frame['FHRisk'] = (((data_frame['FHRisk'] - data_frame['FHRisk'].min()) / (data_frame['FHRisk'].max() - data_frame['FHRisk'].min())) * (max_val - min_val) + min_val).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Age', 'FDR', 'FHRisk']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to make it even more meaningful, we will combine it with the `Risk` feature we engineered using the `AGE` and `BMI` features to create a combined risk 'interaction feature' that captures real-world relationships between the features.\n",
    "\n",
    "Again we will scale the result between 0.15 and 0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age  Risk%  FHRisk  CombRisk\n",
      "2     43   0.10    0.62      0.21\n",
      "3     22   0.05    0.62      0.17\n",
      "4     23   0.06    0.62      0.18\n",
      "5     26   0.07    0.62      0.18\n",
      "8     19   0.05    0.15      0.15\n",
      "..   ...    ...     ...       ...\n",
      "416   43   0.58    0.15      0.24\n",
      "419   57   0.79    0.38      0.48\n",
      "420   55   0.78    0.62      0.69\n",
      "422   69   1.00    0.62      0.85\n",
      "426   37   0.57    0.15      0.24\n",
      "\n",
      "[228 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "data_frame['CombRisk'] = (data_frame['FHRisk'] * data_frame['Risk%']).round(2)\n",
    "\n",
    "min_val = 0.15\n",
    "max_val = 0.85\n",
    "data_frame['CombRisk'] = (((data_frame['CombRisk'] - data_frame['CombRisk'].min()) / (data_frame['CombRisk'].max() - data_frame['CombRisk'].min())) * (max_val - min_val) + min_val).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Age', 'Risk%', 'FHRisk', 'CombRisk']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          BMI        BP    BMI_BP\n",
      "2    0.134615  0.363636  0.048951\n",
      "3    0.138462  0.493506  0.068332\n",
      "4    0.146154  0.246753  0.036064\n",
      "5    0.146154  0.311688  0.045554\n",
      "8    0.161538  0.363636  0.058741\n",
      "..        ...       ...       ...\n",
      "416  0.784615  0.441558  0.346454\n",
      "419  0.811538  0.753247  0.611289\n",
      "420  0.830769  0.701299  0.582617\n",
      "422  0.846154  0.571429  0.483516\n",
      "426  0.896154  0.701299  0.628472\n",
      "\n",
      "[228 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create interaction features\n",
    "data_frame['BMI_Age'] = data_frame['BMI'] * data_frame['Age']\n",
    "data_frame['BP_Age'] = data_frame['BP'] * data_frame['Age']\n",
    "data_frame['BMI_BP'] = data_frame['BMI'] * data_frame['BP']\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['BMI', 'BP', 'BMI_BP']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled and engineered data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../2.3.Model_Training/2.3.1.model_ready_data2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
