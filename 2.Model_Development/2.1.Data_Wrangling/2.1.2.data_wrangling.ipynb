{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../../README.md)\n",
    "\n",
    "### Data Wrangling\n",
    "\n",
    "This is a demonstration of data wrangling using [Pandas](https://pandas.pydata.org/) the library for data analysis and manipulation.\n",
    "\n",
    "This Jupyter Notepad demonstrates different processes you can apply to your data to prepare it for feature engineering and model training. For this demonstration we will wrangle the diabetes data set you previewed in the last Jupyter Notebook.\n",
    "\n",
    "> [!Note]\n",
    "> None of these processes are destructive to the source CSV as long as you save the modified data to a new CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"2.1.2.Diabeties_Sample_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with null values\n",
    "\n",
    "Null values during data analysis can cause runtime errors and unexpected results. It is important to identify null values and deal with them appropriately before training a model.\n",
    "\n",
    "The `isnull().sum()` method call returns the null values in any column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       1\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have null data there are many ways to deal with the empty/null values. These are the two most common approaches.\n",
    "1. Remove any row with a null value with a `dropna()` method call.\n",
    "2. Replace missing values with another value with a `fillna()` method call. Generally, we use mean value for numerical columns because it may cause minimal changes in your mathematical analysis while maintaining the original size of the data.\n",
    "\n",
    "Students should reflect why this example removes the null 'SEX' but replacing the mean 'Target'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       0\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Null values\n",
    "data_frame = data_frame.dropna(subset=['SEX'])\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoB       0\n",
       "DoT       0\n",
       "SEX       0\n",
       "BMI       0\n",
       "BP        0\n",
       "TC        0\n",
       "BGU       0\n",
       "FDR       0\n",
       "Target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace Null values with the mean value for the column\n",
    "data_frame['Target'] = data_frame['Target'].fillna(data_frame['Target'].mean())\n",
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Duplicates\n",
    "\n",
    "Duplicate data can have detrimental effects on your machine learning models and outcomes, such as reducing data diversity and representativeness, which can lead to overfitting or biased models.\n",
    "\n",
    "The `duplicated().sum()` method call returns the count of duplicate rows in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `drop_duplicates()` method call can be then stored back onto the data_frame variable removing the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = data_frame.drop_duplicates()\n",
    "data_frame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace data\n",
    "\n",
    "We can run a lambda function on a column to modify its values. For a simple example, letâ€™s convert the Sex to lowercase. To run a function over a complete column, we can use the apply method which iterates over each row and modifies the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    female\n",
       "1    female\n",
       "2      male\n",
       "3      male\n",
       "4      male\n",
       "Name: SEX, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda x: x.lower())\n",
    "data_frame['SEX'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that there are no data entry errors by the `unique()` method call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male', 'girl'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', 'male'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['SEX'] = data_frame['SEX'].apply(lambda gender: 'male' if gender.lower() == 'male' else 'female')\n",
    "data_frame['SEX'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers\n",
    "\n",
    "Outliers can skew your analysis on numerical columns, and it is important to remove them. We can use the 25th and 75th quartile on numerical data, to get the inter-quartile range. This allows us to estimate an acceptable range, and we can then filter out any values outside this range. Mathematically, outliers are values occurring outside 1.5 times the interquartile range (IQR) from the first quartile (Q1) or third quartile (Q3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    425.000000\n",
      "mean     149.807797\n",
      "std       75.798750\n",
      "min       25.000000\n",
      "25%       86.000000\n",
      "50%      139.000000\n",
      "75%      202.000000\n",
      "max      341.000000\n",
      "Name: Target, dtype: float64\n",
      "Outliers are a BMI above 376.0 or below -88.0\n"
     ]
    }
   ],
   "source": [
    "#get the inter-quartile range on the salary column\n",
    "print(data_frame['Target'].describe())\n",
    "Q1 = data_frame['Target'].quantile(0.25)\n",
    "Q3 = data_frame['Target'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f'Outliers are a BMI above {Q3 + IQR * 1.5} or below {Q1 - IQR * 1.5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    425.000000\n",
      "mean     149.807797\n",
      "std       75.798750\n",
      "min       25.000000\n",
      "25%       86.000000\n",
      "50%      139.000000\n",
      "75%      202.000000\n",
      "max      341.000000\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Filter salaries within the acceptable range\n",
    "data_frame = data_frame[(data_frame['Target'] >= Q1 - 1.5 * IQR) & (data_frame['Target'] <= Q3 + 1.5 * IQR)]\n",
    "print(data_frame['Target'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling features to a common range\n",
    "\n",
    "Scaling the features makes it easier for machine learning algorithms to find the optimal solution, as the different scales of the features do not influence them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    425.000000\n",
      "mean      26.206824\n",
      "std        4.243155\n",
      "min       18.000000\n",
      "25%       23.100000\n",
      "50%       25.600000\n",
      "75%       29.000000\n",
      "max       38.300000\n",
      "Name: BMI, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data_frame['BMI'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "BMI",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BP",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TC",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "BGU",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FDR",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Target",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "037db9d4-e793-4761-bbab-89c4ff83c6c4",
       "rows": [
        [
         "count",
         "427.0",
         "427.0",
         "427.0",
         "427.0",
         "427.0",
         "427.0"
        ],
        [
         "mean",
         "0.43186813186813194",
         "0.46208765473402474",
         "0.3380249804839968",
         "0.46662763466042156",
         "0.265807962529274",
         "0.3995987310491464"
        ],
        [
         "std",
         "0.16330496642339007",
         "0.17684383820770241",
         "0.1418869722588954",
         "0.17761203209528914",
         "0.20743682930572319",
         "0.233290641625014"
        ],
        [
         "min",
         "0.11538461538461539",
         "0.03896103896103896",
         "0.1111111111111111",
         "0.05",
         "0.0",
         "0.015384615384615385"
        ],
        [
         "25%",
         "0.31346153846153846",
         "0.33116883116883117",
         "0.2222222222222222",
         "0.3416666666666667",
         "0.0",
         "0.20153846153846156"
        ],
        [
         "50%",
         "0.4115384615384615",
         "0.44155844155844154",
         "0.3333333333333333",
         "0.4666666666666667",
         "0.25",
         "0.36615384615384616"
        ],
        [
         "75%",
         "0.5423076923076923",
         "0.5974025974025974",
         "0.4444444444444444",
         "0.5833333333333334",
         "0.5",
         "0.5661538461538462"
        ],
        [
         "max",
         "0.8961538461538461",
         "0.961038961038961",
         "0.8988888888888888",
         "0.95",
         "0.75",
         "0.9876923076923076"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>TC</th>\n",
       "      <th>BGU</th>\n",
       "      <th>FDR</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "      <td>427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.431868</td>\n",
       "      <td>0.462088</td>\n",
       "      <td>0.338025</td>\n",
       "      <td>0.466628</td>\n",
       "      <td>0.265808</td>\n",
       "      <td>0.399599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.163305</td>\n",
       "      <td>0.176844</td>\n",
       "      <td>0.141887</td>\n",
       "      <td>0.177612</td>\n",
       "      <td>0.207437</td>\n",
       "      <td>0.233291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.038961</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.313462</td>\n",
       "      <td>0.331169</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.411538</td>\n",
       "      <td>0.441558</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.366154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.542308</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.566154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.896154</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.898889</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.987692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BMI          BP          TC         BGU         FDR      Target\n",
       "count  427.000000  427.000000  427.000000  427.000000  427.000000  427.000000\n",
       "mean     0.431868    0.462088    0.338025    0.466628    0.265808    0.399599\n",
       "std      0.163305    0.176844    0.141887    0.177612    0.207437    0.233291\n",
       "min      0.115385    0.038961    0.111111    0.050000    0.000000    0.015385\n",
       "25%      0.313462    0.331169    0.222222    0.341667    0.000000    0.201538\n",
       "50%      0.411538    0.441558    0.333333    0.466667    0.250000    0.366154\n",
       "75%      0.542308    0.597403    0.444444    0.583333    0.500000    0.566154\n",
       "max      0.896154    0.961039    0.898889    0.950000    0.750000    0.987692"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_feature = 'BMI'\n",
    "\n",
    "#the minimum value with space for outliers\n",
    "MIN_BP = 20\n",
    "\n",
    "#the maximum value with space for outliers\n",
    "MAX_BP = 345\n",
    "\n",
    "#scale features\n",
    "data_frame[scale_feature] = [(X - MIN_BP) / (MAX_BP - MIN_BP) for X in data_frame[scale_feature]]\n",
    "\n",
    "data_frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!important]\n",
    "> You need to save the calculations for each dataset you scale for scaling new values for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../2.2.Feature_Engineering/2.2.1.wrangled_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
